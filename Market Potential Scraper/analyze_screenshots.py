"""
åˆ†æ screenshots ç›®å½•ä¸‹çš„ DataEye API JSON æ•°æ®
ç”Ÿæˆç»´åº¦åˆ†æè¡¨æ ¼
"""

import os
import json
import logging
from datetime import datetime
from typing import Dict, List, Tuple
from collections import defaultdict
import pandas as pd
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
from openpyxl.utils.dataframe import dataframe_to_rows

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ScreenshotAnalyzer:
    """åˆ†æ screenshots ç›®å½•ä¸‹çš„ JSON æ•°æ®"""

    def __init__(self, screenshots_dir: str = "screenshots"):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            screenshots_dir: screenshots ç›®å½•è·¯å¾„
        """
        self.screenshots_dir = screenshots_dir
        self.drama_data = {}  # å­˜å‚¨æ¯ä¸ªå‰§ç›®çš„èšåˆæ•°æ®

    def load_all_json_files(self) -> Dict[str, List[Dict]]:
        """
        åŠ è½½æ‰€æœ‰ JSON æ–‡ä»¶

        Returns:
            å­—å…¸: {å‰§å: [2å¹´æ•°æ®, 30å¤©æ•°æ®]}
        """
        logger.info(f"å¼€å§‹æ‰«æç›®å½•: {self.screenshots_dir}")

        if not os.path.exists(self.screenshots_dir):
            logger.error(f"ç›®å½•ä¸å­˜åœ¨: {self.screenshots_dir}")
            return {}

        # æŒ‰å‰§ååˆ†ç»„
        drama_files = defaultdict(dict)

        for filename in os.listdir(self.screenshots_dir):
            if not filename.endswith('.json'):
                continue

            # è§£ææ–‡ä»¶å: å‰§å_æ—¶é—´çª—å£.json
            if '_2å¹´' in filename:
                drama_name = filename.replace('_2å¹´.json', '')
                time_window = '2å¹´'
            elif '_30å¤©' in filename:
                drama_name = filename.replace('_30å¤©.json', '')
                time_window = '30å¤©'
            else:
                logger.warning(f"æ— æ³•è¯†åˆ«æ–‡ä»¶åæ ¼å¼: {filename}")
                continue

            filepath = os.path.join(self.screenshots_dir, filename)

            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    drama_files[drama_name][time_window] = data
                    logger.info(f"âœ“ åŠ è½½: {filename}")
            except Exception as e:
                logger.error(f"âœ— åŠ è½½å¤±è´¥ {filename}: {e}")

        logger.info(f"âœ“ å…±åŠ è½½ {len(drama_files)} ä¸ªå‰§ç›®çš„æ•°æ®")
        return dict(drama_files)

    def extract_dimensions(self, drama_name: str, data_2y: Dict, data_30d: Dict) -> Dict:
        """
        æå–ç»´åº¦æ•°æ®

        Args:
            drama_name: å‰§å
            data_2y: 2å¹´æ•°æ®
            data_30d: 30å¤©æ•°æ®

        Returns:
            ç»´åº¦æ•°æ®å­—å…¸
        """
        logger.info(f"åˆ†æå‰§ç›®: {drama_name}")

        # æå–ç´ æåˆ—è¡¨
        materials_2y = data_2y.get('content', {}).get('searchList', [])
        materials_30d = data_30d.get('content', {}).get('searchList', []) if data_30d else []

        # åˆå§‹åŒ–ç»´åº¦æ•°æ®
        dimensions = {
            'å‰§å': drama_name,

            # æŠ•æ”¾è§„æ¨¡
            '2å¹´ç´¯è®¡æ›å…‰é‡': 0,
            '2å¹´é¢„ä¼°ä¸‹è½½é‡': 0,
            '30å¤©ç´¯è®¡æ›å…‰é‡': 0,
            '30å¤©é¢„ä¼°ä¸‹è½½é‡': 0,

            # ç´ ææ•°
            '2å¹´ç´ ææ€»æ•°': len(materials_2y),
            '30å¤©åœ¨æŠ•ç´ ææ•°': len(materials_30d),

            # åœ°åŒºåˆ†å¸ƒ
            'æŠ•æ”¾å›½å®¶æ•°_2å¹´': 0,
            'æŠ•æ”¾å›½å®¶æ•°_30å¤©': 0,
            'Top5å›½å®¶_2å¹´': [],
            'Top5å›½å®¶_30å¤©': [],

            # å¹³å°åˆ†å¸ƒ
            'æŠ•æ”¾å¹³å°åˆ†å¸ƒ_2å¹´': {},
            'æŠ•æ”¾å¹³å°åˆ†å¸ƒ_30å¤©': {},

            # ç´ æå½¢å¼
            'ç´ æå½¢å¼å æ¯”_2å¹´': {},
            'ç´ æå½¢å¼å æ¯”_30å¤©': {},

            # åˆ¶ä½œæ–¹
            'ä¸»è¦åˆ¶ä½œæ–¹_2å¹´': [],
            'ä¸»è¦åˆ¶ä½œæ–¹_30å¤©': [],

            # ç”Ÿå‘½å‘¨æœŸ
            'é¦–æ¬¡æŠ•æ”¾æ—¥æœŸ': None,
            'æœ€åæŠ•æ”¾æ—¥æœŸ': None,
            'ç”Ÿå‘½å‘¨æœŸå¤©æ•°': 0,
            'æ´»è·ƒå¤©æ•°': 0,
        }

        # åˆ†æ 2å¹´æ•°æ®
        if materials_2y:
            dimensions.update(self._analyze_materials(materials_2y, '2å¹´'))

        # åˆ†æ 30å¤©æ•°æ®
        if materials_30d:
            dimensions.update(self._analyze_materials(materials_30d, '30å¤©'))

        return dimensions

    def _analyze_materials(self, materials: List[Dict], time_window: str) -> Dict:
        """
        åˆ†æç´ æåˆ—è¡¨ï¼Œæå–ç»´åº¦æ•°æ®

        Args:
            materials: ç´ æåˆ—è¡¨
            time_window: æ—¶é—´çª—å£ ('2å¹´' æˆ– '30å¤©')

        Returns:
            ç»´åº¦æ•°æ®å­—å…¸
        """
        result = {}

        # ç»Ÿè®¡å˜é‡
        total_exposure = 0
        total_downloads = 0
        country_stats = defaultdict(int)  # å›½å®¶ -> æ›å…‰é‡
        platform_stats = defaultdict(int)  # å¹³å° -> ç´ ææ•°
        material_type_stats = defaultdict(int)  # ç´ æç±»å‹ -> ç´ ææ•°
        publisher_stats = defaultdict(int)  # åˆ¶ä½œæ–¹ -> ç´ ææ•°
        first_seen_dates = []
        last_seen_dates = []
        active_days_set = set()

        # éå†ç´ æ
        for material in materials:
            # æ›å…‰é‡å’Œä¸‹è½½é‡
            exposure = material.get('exposureNum', 0)
            downloads = material.get('downloadNum', 0)
            total_exposure += exposure
            total_downloads += downloads

            # å›½å®¶ç»Ÿè®¡
            countries = material.get('countries', [])
            for country in countries:
                country_name = country.get('countryName', 'æœªçŸ¥')
                country_stats[country_name] += exposure

            # å¹³å°ç»Ÿè®¡
            media = material.get('media', {})
            if media:
                platform_name = media.get('mediaName', 'æœªçŸ¥')
                platform_stats[platform_name] += 1

            # ç´ æç±»å‹ç»Ÿè®¡
            material_type = material.get('materialType', 0)
            type_name = 'è§†é¢‘' if material_type == 2 else 'å›¾ç‰‡'
            material_type_stats[type_name] += 1

            # åˆ¶ä½œæ–¹ç»Ÿè®¡
            publisher = material.get('publisher', {})
            if publisher:
                publisher_name = publisher.get('publisherName', 'æœªçŸ¥')
                publisher_stats[publisher_name] += 1

            # æ—¶é—´ç»Ÿè®¡
            first_seen = material.get('firstSeen', '')
            last_seen = material.get('lastSeen', '')
            if first_seen:
                first_seen_dates.append(first_seen)
            if last_seen:
                last_seen_dates.append(last_seen)

            # æ´»è·ƒå¤©æ•°
            release_days = material.get('releaseDay', 0)
            if first_seen and release_days > 0:
                try:
                    from datetime import datetime, timedelta
                    start_date = datetime.strptime(first_seen, '%Y-%m-%d')
                    for i in range(release_days):
                        day = start_date + timedelta(days=i)
                        active_days_set.add(day.strftime('%Y-%m-%d'))
                except:
                    pass

        # æ±‡æ€»ç»“æœ
        suffix = f'_{time_window}'

        result[f'ç´¯è®¡æ›å…‰é‡{suffix}'] = total_exposure
        result[f'é¢„ä¼°ä¸‹è½½é‡{suffix}'] = total_downloads

        # Top 5 å›½å®¶
        top_countries = sorted(country_stats.items(), key=lambda x: x[1], reverse=True)[:5]
        result[f'æŠ•æ”¾å›½å®¶æ•°{suffix}'] = len(country_stats)
        result[f'Top5å›½å®¶{suffix}'] = [f"{c[0]}({c[1]:,})" for c in top_countries]

        # å¹³å°åˆ†å¸ƒ
        result[f'æŠ•æ”¾å¹³å°åˆ†å¸ƒ{suffix}'] = dict(platform_stats)

        # ç´ æå½¢å¼å æ¯”
        result[f'ç´ æå½¢å¼å æ¯”{suffix}'] = dict(material_type_stats)

        # Top 3 åˆ¶ä½œæ–¹
        top_publishers = sorted(publisher_stats.items(), key=lambda x: x[1], reverse=True)[:3]
        result[f'ä¸»è¦åˆ¶ä½œæ–¹{suffix}'] = [f"{p[0]}({p[1]})" for p in top_publishers]

        # ç”Ÿå‘½å‘¨æœŸï¼ˆä»…2å¹´æ•°æ®è®¡ç®—ï¼‰
        if time_window == '2å¹´' and first_seen_dates and last_seen_dates:
            result['é¦–æ¬¡æŠ•æ”¾æ—¥æœŸ'] = min(first_seen_dates)
            result['æœ€åæŠ•æ”¾æ—¥æœŸ'] = max(last_seen_dates)
            try:
                from datetime import datetime
                first = datetime.strptime(min(first_seen_dates), '%Y-%m-%d')
                last = datetime.strptime(max(last_seen_dates), '%Y-%m-%d')
                result['ç”Ÿå‘½å‘¨æœŸå¤©æ•°'] = (last - first).days
                result['æ´»è·ƒå¤©æ•°'] = len(active_days_set)
            except:
                pass

        return result

    def generate_excel_report(self, output_file: str = "ç»´åº¦åˆ†ææŠ¥å‘Š.xlsx"):
        """
        ç”Ÿæˆ Excel åˆ†ææŠ¥å‘Š

        Args:
            output_file: è¾“å‡ºæ–‡ä»¶å
        """
        logger.info(f"å¼€å§‹ç”Ÿæˆ Excel æŠ¥å‘Š: {output_file}")

        # åŠ è½½æ‰€æœ‰ JSON æ•°æ®
        drama_files = self.load_all_json_files()

        if not drama_files:
            logger.error("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ•°æ®æ–‡ä»¶")
            return

        # æå–æ‰€æœ‰å‰§ç›®çš„ç»´åº¦æ•°æ®
        all_dimensions = []
        for drama_name, files in drama_files.items():
            data_2y = files.get('2å¹´')
            data_30d = files.get('30å¤©')

            if not data_2y:
                logger.warning(f"å‰§ç›® {drama_name} ç¼ºå°‘2å¹´æ•°æ®ï¼Œè·³è¿‡")
                continue

            dimensions = self.extract_dimensions(drama_name, data_2y, data_30d)
            all_dimensions.append(dimensions)

        if not all_dimensions:
            logger.error("æ²¡æœ‰æå–åˆ°ä»»ä½•ç»´åº¦æ•°æ®")
            return

        # åˆ›å»º Excel å·¥ä½œç°¿
        wb = Workbook()
        wb.remove(wb.active)  # åˆ é™¤é»˜è®¤ sheet

        # Sheet 1: ç»´åº¦æ±‡æ€»è¡¨
        self._create_summary_sheet(wb, all_dimensions)

        # Sheet 2: è¯¦ç»†æ•°æ®æ˜ç»†
        self._create_detail_sheet(wb, all_dimensions)

        # Sheet 3: åˆ¶ä½œæ–¹åˆ†æ
        self._create_publisher_sheet(wb, all_dimensions)

        # ä¿å­˜æ–‡ä»¶
        wb.save(output_file)
        logger.info(f"âœ“ Excel æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")

    def _create_summary_sheet(self, wb: Workbook, all_dimensions: List[Dict]):
        """åˆ›å»ºç»´åº¦æ±‡æ€»è¡¨"""
        ws = wb.create_sheet("ç»´åº¦æ±‡æ€»è¡¨", 0)

        # å®šä¹‰è¡¨å¤´
        headers = [
            'å‰§å',
            '2å¹´ç´¯è®¡æ›å…‰é‡',
            '30å¤©ç´¯è®¡æ›å…‰é‡',
            '2å¹´ç´ ææ€»æ•°',
            '30å¤©åœ¨æŠ•ç´ ææ•°',
            'ç”Ÿå‘½å‘¨æœŸå¤©æ•°',
            'æ´»è·ƒå¤©æ•°',
            'æŠ•æ”¾å›½å®¶æ•°_2å¹´',
            'Top5å›½å®¶_2å¹´',
            'ä¸»è¦åˆ¶ä½œæ–¹_2å¹´',
            'é¦–æ¬¡æŠ•æ”¾æ—¥æœŸ',
            'æœ€åæŠ•æ”¾æ—¥æœŸ',
        ]

        # å†™å…¥è¡¨å¤´
        for col_idx, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col_idx, value=header)
            cell.font = Font(bold=True, size=11)
            cell.fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
            cell.font = Font(bold=True, color="FFFFFF", size=11)
            cell.alignment = Alignment(horizontal='center', vertical='center')

        # å†™å…¥æ•°æ®
        for row_idx, dim in enumerate(all_dimensions, 2):
            ws.cell(row=row_idx, column=1, value=dim.get('å‰§å', ''))
            ws.cell(row=row_idx, column=2, value=dim.get('ç´¯è®¡æ›å…‰é‡_2å¹´', 0))
            ws.cell(row=row_idx, column=3, value=dim.get('ç´¯è®¡æ›å…‰é‡_30å¤©', 0))
            ws.cell(row=row_idx, column=4, value=dim.get('2å¹´ç´ ææ€»æ•°', 0))
            ws.cell(row=row_idx, column=5, value=dim.get('30å¤©åœ¨æŠ•ç´ ææ•°', 0))
            ws.cell(row=row_idx, column=6, value=dim.get('ç”Ÿå‘½å‘¨æœŸå¤©æ•°', 0))
            ws.cell(row=row_idx, column=7, value=dim.get('æ´»è·ƒå¤©æ•°', 0))
            ws.cell(row=row_idx, column=8, value=dim.get('æŠ•æ”¾å›½å®¶æ•°_2å¹´', 0))
            ws.cell(row=row_idx, column=9, value='\n'.join(dim.get('Top5å›½å®¶_2å¹´', [])))
            ws.cell(row=row_idx, column=10, value='\n'.join(dim.get('ä¸»è¦åˆ¶ä½œæ–¹_2å¹´', [])))
            ws.cell(row=row_idx, column=11, value=dim.get('é¦–æ¬¡æŠ•æ”¾æ—¥æœŸ', ''))
            ws.cell(row=row_idx, column=12, value=dim.get('æœ€åæŠ•æ”¾æ—¥æœŸ', ''))

        # è°ƒæ•´åˆ—å®½
        ws.column_dimensions['A'].width = 30
        ws.column_dimensions['B'].width = 15
        ws.column_dimensions['C'].width = 15
        ws.column_dimensions['D'].width = 12
        ws.column_dimensions['E'].width = 15
        ws.column_dimensions['F'].width = 12
        ws.column_dimensions['G'].width = 10
        ws.column_dimensions['H'].width = 12
        ws.column_dimensions['I'].width = 30
        ws.column_dimensions['J'].width = 35
        ws.column_dimensions['K'].width = 15
        ws.column_dimensions['L'].width = 15

        logger.info("âœ“ å·²åˆ›å»ºç»´åº¦æ±‡æ€»è¡¨")

    def _create_detail_sheet(self, wb: Workbook, all_dimensions: List[Dict]):
        """åˆ›å»ºè¯¦ç»†æ•°æ®æ˜ç»†è¡¨"""
        ws = wb.create_sheet("è¯¦ç»†æ•°æ®æ˜ç»†", 1)

        # å®šä¹‰è¡¨å¤´
        headers = [
            'å‰§å',
            '2å¹´ç´¯è®¡æ›å…‰é‡',
            '2å¹´é¢„ä¼°ä¸‹è½½é‡',
            '2å¹´ç´ ææ€»æ•°',
            '30å¤©ç´¯è®¡æ›å…‰é‡',
            '30å¤©é¢„ä¼°ä¸‹è½½é‡',
            '30å¤©åœ¨æŠ•ç´ ææ•°',
            'ç”Ÿå‘½å‘¨æœŸå¤©æ•°',
            'æ´»è·ƒå¤©æ•°',
            'é¦–æ¬¡æŠ•æ”¾æ—¥æœŸ',
            'æœ€åæŠ•æ”¾æ—¥æœŸ',
            'æŠ•æ”¾å›½å®¶æ•°_2å¹´',
            'æŠ•æ”¾å›½å®¶æ•°_30å¤©',
            'Top5å›½å®¶_2å¹´',
            'Top5å›½å®¶_30å¤©',
            'æŠ•æ”¾å¹³å°_2å¹´',
            'æŠ•æ”¾å¹³å°_30å¤©',
            'ç´ æå½¢å¼_2å¹´',
            'ç´ æå½¢å¼_30å¤©',
        ]

        # å†™å…¥è¡¨å¤´
        for col_idx, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col_idx, value=header)
            cell.font = Font(bold=True, color="FFFFFF", size=11)
            cell.fill = PatternFill(start_color="70AD47", end_color="70AD47", fill_type="solid")
            cell.alignment = Alignment(horizontal='center', vertical='center')

        # å†™å…¥æ•°æ®
        for row_idx, dim in enumerate(all_dimensions, 2):
            ws.cell(row=row_idx, column=1, value=dim.get('å‰§å', ''))
            ws.cell(row=row_idx, column=2, value=dim.get('ç´¯è®¡æ›å…‰é‡_2å¹´', 0))
            ws.cell(row=row_idx, column=3, value=dim.get('é¢„ä¼°ä¸‹è½½é‡_2å¹´', 0))
            ws.cell(row=row_idx, column=4, value=dim.get('2å¹´ç´ ææ€»æ•°', 0))
            ws.cell(row=row_idx, column=5, value=dim.get('ç´¯è®¡æ›å…‰é‡_30å¤©', 0))
            ws.cell(row=row_idx, column=6, value=dim.get('é¢„ä¼°ä¸‹è½½é‡_30å¤©', 0))
            ws.cell(row=row_idx, column=7, value=dim.get('30å¤©åœ¨æŠ•ç´ ææ•°', 0))
            ws.cell(row=row_idx, column=8, value=dim.get('ç”Ÿå‘½å‘¨æœŸå¤©æ•°', 0))
            ws.cell(row=row_idx, column=9, value=dim.get('æ´»è·ƒå¤©æ•°', 0))
            ws.cell(row=row_idx, column=10, value=dim.get('é¦–æ¬¡æŠ•æ”¾æ—¥æœŸ', ''))
            ws.cell(row=row_idx, column=11, value=dim.get('æœ€åæŠ•æ”¾æ—¥æœŸ', ''))
            ws.cell(row=row_idx, column=12, value=dim.get('æŠ•æ”¾å›½å®¶æ•°_2å¹´', 0))
            ws.cell(row=row_idx, column=13, value=dim.get('æŠ•æ”¾å›½å®¶æ•°_30å¤©', 0))
            ws.cell(row=row_idx, column=14, value='\n'.join(dim.get('Top5å›½å®¶_2å¹´', [])))
            ws.cell(row=row_idx, column=15, value='\n'.join(dim.get('Top5å›½å®¶_30å¤©', [])))

            # å¹³å°åˆ†å¸ƒ
            platform_2y = dim.get('æŠ•æ”¾å¹³å°åˆ†å¸ƒ_2å¹´', {})
            platform_str_2y = '\n'.join([f"{k}: {v}" for k, v in platform_2y.items()])
            ws.cell(row=row_idx, column=16, value=platform_str_2y)

            platform_30d = dim.get('æŠ•æ”¾å¹³å°åˆ†å¸ƒ_30å¤©', {})
            platform_str_30d = '\n'.join([f"{k}: {v}" for k, v in platform_30d.items()])
            ws.cell(row=row_idx, column=17, value=platform_str_30d)

            # ç´ æå½¢å¼
            material_2y = dim.get('ç´ æå½¢å¼å æ¯”_2å¹´', {})
            material_str_2y = '\n'.join([f"{k}: {v}" for k, v in material_2y.items()])
            ws.cell(row=row_idx, column=18, value=material_str_2y)

            material_30d = dim.get('ç´ æå½¢å¼å æ¯”_30å¤©', {})
            material_str_30d = '\n'.join([f"{k}: {v}" for k, v in material_30d.items()])
            ws.cell(row=row_idx, column=19, value=material_str_30d)

        # è°ƒæ•´åˆ—å®½
        for col in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M']:
            ws.column_dimensions[col].width = 15
        ws.column_dimensions['A'].width = 30
        ws.column_dimensions['N'].width = 30
        ws.column_dimensions['O'].width = 30
        ws.column_dimensions['P'].width = 25
        ws.column_dimensions['Q'].width = 25
        ws.column_dimensions['R'].width = 20
        ws.column_dimensions['S'].width = 20

        logger.info("âœ“ å·²åˆ›å»ºè¯¦ç»†æ•°æ®æ˜ç»†è¡¨")

    def _create_publisher_sheet(self, wb: Workbook, all_dimensions: List[Dict]):
        """åˆ›å»ºåˆ¶ä½œæ–¹åˆ†æè¡¨"""
        ws = wb.create_sheet("åˆ¶ä½œæ–¹åˆ†æ", 2)

        # æ”¶é›†æ‰€æœ‰åˆ¶ä½œæ–¹æ•°æ®
        publisher_drama_map = defaultdict(list)  # åˆ¶ä½œæ–¹ -> [å‰§ååˆ—è¡¨]

        for dim in all_dimensions:
            drama_name = dim.get('å‰§å', '')
            publishers_2y = dim.get('ä¸»è¦åˆ¶ä½œæ–¹_2å¹´', [])

            for pub_str in publishers_2y:
                # è§£æ "åˆ¶ä½œæ–¹åç§°(ç´ ææ•°)" æ ¼å¼
                if '(' in pub_str:
                    pub_name = pub_str.split('(')[0]
                    publisher_drama_map[pub_name].append(drama_name)

        # å®šä¹‰è¡¨å¤´
        headers = ['åˆ¶ä½œæ–¹', 'æŠ•æ”¾å‰§ç›®æ•°', 'å‰§ç›®åˆ—è¡¨', 'å†³ç­–ä»·å€¼']

        # å†™å…¥è¡¨å¤´
        for col_idx, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col_idx, value=header)
            cell.font = Font(bold=True, color="FFFFFF", size=11)
            cell.fill = PatternFill(start_color="FFC000", end_color="FFC000", fill_type="solid")
            cell.alignment = Alignment(horizontal='center', vertical='center')

        # æŒ‰å‰§ç›®æ•°æ’åº
        sorted_publishers = sorted(publisher_drama_map.items(), key=lambda x: len(x[1]), reverse=True)

        # å†™å…¥æ•°æ®
        for row_idx, (publisher, dramas) in enumerate(sorted_publishers, 2):
            ws.cell(row=row_idx, column=1, value=publisher)
            ws.cell(row=row_idx, column=2, value=len(dramas))
            ws.cell(row=row_idx, column=3, value='\n'.join(dramas))

            # å†³ç­–ä»·å€¼åˆ¤æ–­
            decision_value = self._evaluate_publisher(publisher, len(dramas))
            ws.cell(row=row_idx, column=4, value=decision_value)

        # è°ƒæ•´åˆ—å®½
        ws.column_dimensions['A'].width = 35
        ws.column_dimensions['B'].width = 12
        ws.column_dimensions['C'].width = 40
        ws.column_dimensions['D'].width = 50

        logger.info("âœ“ å·²åˆ›å»ºåˆ¶ä½œæ–¹åˆ†æè¡¨")

    def _evaluate_publisher(self, publisher_name: str, drama_count: int) -> str:
        """
        è¯„ä¼°åˆ¶ä½œæ–¹çš„å†³ç­–ä»·å€¼

        Args:
            publisher_name: åˆ¶ä½œæ–¹åç§°
            drama_count: æŠ•æ”¾å‰§ç›®æ•°

        Returns:
            å†³ç­–ä»·å€¼æè¿°
        """
        # Sçº§åˆ¶ä½œæ–¹ï¼ˆå¤´éƒ¨ç©å®¶ï¼‰
        s_tier_publishers = ['ReelShort', 'DramaBox', 'FlexTV', 'ShortMax', 'MoboReels']

        for s_pub in s_tier_publishers:
            if s_pub.lower() in publisher_name.lower():
                return f"â­ Sçº§åˆ¶ä½œæ–¹ - å¤´éƒ¨ç©å®¶æ­£åœ¨æŠ•æ”¾ï¼ŒéªŒè¯è¿‡çš„ä¼˜è´¨å‰§ç›®"

        # é«˜é¢‘æŠ•æ”¾æ–¹
        if drama_count >= 5:
            return f"ğŸ”¥ é«˜é¢‘æŠ•æ”¾ - è¯¥åˆ¶ä½œæ–¹æŠ•æ”¾{drama_count}éƒ¨å‰§ï¼Œå¯èƒ½æ˜¯ä¸“ä¸šå›¢é˜Ÿ"
        elif drama_count >= 3:
            return f"ğŸ“Š ä¸­ç­‰æŠ•æ”¾ - è¯¥åˆ¶ä½œæ–¹æŠ•æ”¾{drama_count}éƒ¨å‰§"
        else:
            return f"ğŸ“Œ å°è§„æ¨¡æŠ•æ”¾ - è¯¥åˆ¶ä½œæ–¹æŠ•æ”¾{drama_count}éƒ¨å‰§"


def main():
    """ä¸»å‡½æ•°"""
    logger.info("="*60)
    logger.info("DataEye Screenshots æ•°æ®åˆ†æå·¥å…·")
    logger.info("="*60)

    # åˆ›å»ºåˆ†æå™¨
    analyzer = ScreenshotAnalyzer(screenshots_dir="screenshots")

    # ç”Ÿæˆ Excel æŠ¥å‘Š
    output_file = f"ç»´åº¦åˆ†ææŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    analyzer.generate_excel_report(output_file)

    logger.info("="*60)
    logger.info("åˆ†æå®Œæˆï¼")
    logger.info("="*60)


if __name__ == "__main__":
    main()
